# Robo-Pointer Visuel (SO-ARM100 / LeRobot)

[![License: Apache 2.0](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)

**Statut du Projet : üõ†Ô∏è Travail en Cours / D√©bogage Actif üõ†Ô∏è**

Ce projet vise √† contr√¥ler un bras robotique SO-ARM100 (version LeRobot/Hugging Face) √† l'aide d'une cam√©ra mont√©e sur le poignet ("eye-in-hand") pour d√©tecter et suivre un objet de couleur rouge. Il s'agit d'un projet personnel d'apprentissage dans le cadre d'une reconversion vers la robotique logicielle.

**Objectif Principal :**
Impl√©menter un syst√®me de visuo-servage simple mais fonctionnel en utilisant ROS 2 Humble, Python et OpenCV.

**√âtat Actuel (Branche `main` ‚Äî Mai 2025) :**

* L'architecture ROS 2 (3 n≈ìuds principaux) est en place et communique.
* D√©tection d‚Äôobjet rouge basique via OpenCV (filtrage HSV) fonctionnelle.
* Interface bas niveau avec les moteurs Feetech (`scservo_sdk` + `lerobot`) √©tablie, utilisant `GroupSyncRead`/`GroupSyncWrite`.
* Calibration manuelle des moteurs via un fichier JSON.
* Contr√¥le **Pan (horizontal)** via un contr√¥leur Proportionnel.
* **Cin√©matique Directe (FK)** et **Inverse (IK)** pour le plan vertical (√©paule/coude) impl√©ment√©e.
* **Contr√¥leur PI** pour l‚Äôaxe Y cart√©sien impl√©ment√©.
* Compensation d‚Äôerreur angulaire locale (PI) pour le moteur de l‚Äô√©paule (ID 2).
* **D√©fi Actuel :** tuning et stabilisation du contr√¥le vertical (moteur √©paule ID 2 peinant √† monter contre la gravit√©). Ajustement des gains PI local et exploration d‚Äôune compensation de gravit√© explicite.

---

## Table des Mati√®res

* [Mat√©riel Requis](#mat√©riel-requis)
* [Logiciels Requis](#logiciels-requis)
* [Installation](#installation)

  * [1. Cloner le D√©p√¥t](#1-cloner-le-d√©p√¥t)
  * [2. Environnement Conda](#2-environnement-conda)
  * [3. Installer LeRobot](#3-installer-lerobot)
  * [4. Workspace ROS 2](#4-workspace-ros-2)
  * [5. Calibration Manuelle (Crucial !)](#5-calibration-manuelle-crucial-)
  * [6. R√®gles Udev (Recommand√©)](#6-r√®gles-udev-recommand√©)
  * [7. Permissions](#7-permissions)
* [Utilisation](#utilisation)
* [Structure du Projet](#structure-du-projet)
* [Prochaines √âtapes](#prochaines-√©tapes)
* [Licence](#licence)
* [Contact](#contact)
* [D√©p√¥t Mat√©riel SO-ARM100](#d√©p√¥t-mat√©riel-so-arm100)

---

## Mat√©riel Requis

* Bras Robotique SO-ARM100 (version LeRobot/Hugging Face avec moteurs Feetech STS3215)
* Adaptateur U2D2 ou interface similaire pour les moteurs Feetech
* Cam√©ra USB (test√© avec Innomaker 1080P)
* Alimentation 5 V, \~5 A pour les moteurs
* Objet rouge vif pour la d√©tection
* PC sous Ubuntu 22.04

## Logiciels Requis

* Ubuntu 22.04 LTS
* ROS 2 Humble Hawksbill (`ros-humble-desktop`)
* Miniconda ou Anaconda
* Git
* Tmux

## Installation

### 1. Cloner le D√©p√¥t

```bash
# Adaptez ~/ros2_ws si votre workspace est ailleurs
git clone https://github.com/bkoensgen/robo-pointer-so100.git ~/ros2_ws/src/robo-pointer-so100
```

### 2. Environnement Conda

```bash
# Si vous n'avez pas d√©j√† l'environnement de LeRobot
# conda create -n lerobot python=3.10
conda activate lerobot
```

### 3. Installer LeRobot

```bash
# Adaptez ~/lerobot si vous l'avez clon√© ailleurs
git clone https://github.com/huggingface/lerobot.git ~/lerobot
cd ~/lerobot
pip install -e .
cd -  # Retour au dossier pr√©c√©dent
```

### 4. Workspace ROS 2

```bash
cd ~/ros2_ws
# Construire seulement ce package
colcon build --packages-select robo_pointer_visual
# Ou simplement `colcon build` pour tout reconstruire
```

Puis, ajoutez dans votre `~/.bashrc` si ce n‚Äôest pas d√©j√† fait :

```bash
source ~/ros2_ws/install/setup.bash
```

### 5. Calibration Manuelle (Crucial !)

* Cr√©ez le fichier `~/.cache/lerobot/calibrations/so100/main_follower.json`
* Contient `motor_names`, `homing_offset`, `drive_mode`, `calib_mode`, etc.
* `homing_offset` = inverse des steps bruts mesur√©s au point z√©ro physique.
* `drive_mode` typique : `[0,1,0,0,1,0]` pour `[Pan,Lift,Elbow,WristFlex,WristRoll,Gripper]`.
* Inspirez-vous de la calibration automatique de `lerobot`, mais mesurez et corrigez manuellement.
* Cr√©ez les dossiers si n√©cessaire :

```bash
mkdir -p ~/.cache/lerobot/calibrations/so100
```

### 6. R√®gles Udev (Recommand√©)

Cr√©ez `/etc/udev/rules.d/99-robot-devices.rules` :

```udev
# Feetech U2D2 Adapter
SUBSYSTEM=="tty", ATTRS{product}=="*U2D2*", ATTRS{serial}=="YOUR_U2D2_SERIAL", SYMLINK+="robot_arm", MODE="0666"

# USB Camera (Exemple g√©n√©rique)
SUBSYSTEM=="video4linux", KERNEL=="video[0-9]*", ATTRS{idVendor}=="XXXX", ATTRS{idProduct}=="YYYY", ATTRS{serial}=="CAMERA_SERIAL", SYMLINK+="robot_camera", MODE="0666"
```

Rechargez les r√®gles :

```bash
sudo udevadm control --reload-rules && sudo udevadm trigger
```

### 7. Permissions

Ajoutez votre utilisateur aux groupes :

```bash
sudo usermod -aG dialout $USER
sudo usermod -aG video  $USER
```

> **Important :** d√©connectez-vous puis reconnectez-vous pour que les changements prennent effet.

## Utilisation

Rendez le script de lancement ex√©cutable et lancez-le :

```bash
chmod +x ~/ros2_ws/start_robot.sh
cd ~/ros2_ws
./start_robot.sh
```

Le script cr√©e une session `tmux` nomm√©e `robot_dev` avec trois panneaux :

1. `vision_node`
2. `robot_controller_node`
3. `real_robot_interface` (logs en `~/real_robot_interface_test1.log`)

Commandes `tmux` utiles :

* D√©tacher : `Ctrl+b` puis `d`
* R√©-attacher : `tmux attach -t robot_dev`
* Tuer la session : `tmux kill-session -t robot_dev`

## Structure du Projet

Le dossier `~/ros2_ws/src/robo_pointer_visual/robo_pointer_visual/` contient :

* **vision\_node.py** : acquisition d‚Äôimage, d√©tection couleur, publication.
* **robot\_controller\_node.py** : calcul d‚Äôerreur visuelle, publication signal P.
* **real\_robot\_interface.py** : interface moteurs Feetech, calibration, FK/IK, contr√¥leurs PI, `GroupSyncWrite`.
* **kinematics.py** : fonctions FK/IK 2-DOF.
* **start\_robot.sh** : script de lancement.

## Prochaines √âtapes

* Ajuster les gains PI locaux (√©paule ID 2) pour stabiliser le contr√¥le vertical.
* Explorer une compensation de gravit√© explicite (URDF ou manuelle).
* Affiner les gains globaux pour un suivi fluide.
* Am√©liorer la d√©tection visuelle.
* Nettoyer le code et la documentation.
* Ajouter des tests automatis√©s.
* Cr√©er des d√©monstrations visuelles.

## Licence

Sous licence Apache 2.0. Voir le fichier `LICENSE`.

## Contact

Benjamin Koensgen ‚Äì [b.koensgen@gmail.com](mailto:b.koensgen@gmail.com)
LinkedIn : linkedin.com/in/benjamin-koensgen

## D√©p√¥t Mat√©riel SO-ARM100

Pour la documentation et les fichiers CAD/URDF du SO-ARM100 (et SO-101), consultez √©galement :
[https://github.com/TheRobotStudio/SO-ARM100](https://github.com/TheRobotStudio/SO-ARM100)
